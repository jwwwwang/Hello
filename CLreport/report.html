<!DOCTYPE html>
<html>
<head>
<title>report.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
	font-size: 14px;
	padding: 0 12px;
	line-height: 22px;
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}


body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	color: #4080D0;
	text-decoration: none;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

h1 code,
h2 code,
h3 code,
h4 code,
h5 code,
h6 code {
	font-size: inherit;
	line-height: auto;
}

a:hover {
	color: #4080D0;
	text-decoration: underline;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left: 5px solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 14px;
	line-height: 19px;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

.mac code {
	font-size: 12px;
	line-height: 18px;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

/** Theming */

.vscode-light,
.vscode-light pre code {
	color: rgb(30, 30, 30);
}

.vscode-dark,
.vscode-dark pre code {
	color: #DDD;
}

.vscode-high-contrast,
.vscode-high-contrast pre code {
	color: white;
}

.vscode-light code {
	color: #A31515;
}

.vscode-dark code {
	color: #D7BA7D;
}

.vscode-light pre:not(.hljs),
.vscode-light code > div {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre:not(.hljs),
.vscode-dark code > div {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre:not(.hljs),
.vscode-high-contrast code > div {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

.vscode-light blockquote,
.vscode-dark blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.vscode-high-contrast blockquote {
	background: transparent;
	border-color: #fff;
}
</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family:  "Meiryo", "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

</head>
<body>
<h1 id="center%E8%AE%A1%E7%AE%97%E8%AF%AD%E8%A8%80%E5%AD%A6%E5%A4%A7%E4%BD%9C%E4%B8%9Acenter"><center>计算语言学大作业</center></h1>
<h2 id="center%E4%BD%BF%E7%94%A8bi-lstmcrf%E8%BF%9B%E8%A1%8C%E4%B8%AD%E6%96%87%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%ABcenter"><center>使用Bi-LSTM+CRF进行中文命名实体识别</center></h2>
<center>金函琪 180121xxxx xxxx@xxxx.com</center>
<center>王君 1801214001 wj96006@163.com</center>
<h2 id="1-%E9%A2%98%E7%9B%AE%E6%8E%A2%E7%B4%A2">1. 题目探索</h2>
<h3 id="11-%E4%B8%AD%E6%96%87%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E5%92%8C%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB">1.1 中文命名实体和实体识别</h3>
<p>一切具有特定属性集合的物体都可以称为实体，中文命名实体一般包括三大类（实体类、时间类、数字类），七小类（人名、机构名、地名、时间、日期、货币和百分比）。</p>
<p>命名实体识别(Named Entities Recognition, NER)是自然语言处理的一个基础任务，其目的是识别语料中人名、地名、组织机构名等命名实体并加以归类，在所有涉及NLP的任务中——譬如信息抽取、信息检索、机器翻——都是一个必须首先攻克的任务。</p>
<p>在本次项目中，位置标签共有两种：</p>
<ul>
<li>B- : 命名实体的首词语</li>
<li>I- : 命名实体首词之后的词</li>
</ul>
<p>标记内容共有三种：</p>
<ul>
<li>PER: 人名</li>
<li>LOC: 地名</li>
<li>ORG: 组织机构名</li>
<li>O: 其他非命名实体的字</li>
</ul>
<h3 id="12-%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E7%8E%B0%E6%9C%89%E6%96%B9%E6%B3%95">1.2 实体识别现有方法</h3>
<p>现有的实体识别方法主要有四种，基于规则的方法、基于统计机器学习的方法和深度学习方法</p>
<ul>
<li>
<p>基于规则的方法：</p>
<ul>
<li>早期的实体识别研究，人工构建有限规则，再从文本中寻找匹配这些规则的字符串，是一种主流的方法。研究者们试图借助机器自动地发现和生成规则，再根据语料对规则集合进行无监督的训练迭代得到更多的规则，最终将规则集用于命名实体的分类，该方法对命名实体三种类别(人名、地名和机构名) 的分类准确率均超过了91%。类似的还有使用Bootstrapping进行规则自动生成的方法，和规则和统计模型相结合的实体识别方法。</li>
<li>基于规则的方法虽然能够在特定的语料上获得较高的识别效果。</li>
<li>但是基于规则的方法依赖大量规则的制定，而人工制定这些规则可行性太低。规则对领域知识的极度依赖，使得当领域差别很大时，制定的规则往往无法移植。对这种方法的广泛应用产生了负面影响。</li>
</ul>
</li>
<li>
<p>基于统计机器学习的方法：</p>
<ul>
<li>大体分为以下几个方向：选择合适的模型和方法，进行模型和方法的改进，选择合适的特征，多种方法的综合。</li>
<li>选择合适的模型和方法：有两种思路，一种是先识别出文本中所有命名实体的边界，再对这些命名实体进行分类；另一种是序列化标注方法。对于文本中每个词，可以有若干个候选的类别标签，这些标签对应于其在各类命名实体中所处的位置，对文本中的每个词进行序列化的自动标注，整合后获得有若干个词构成的命名实体及其类别。</li>
<li>模型方法改进：改进模型并提高模型的计算效率。根据汉语特点调整和优化经典模型，能够更有效地识别汉语文本中的命名实体，如层叠马尔可夫方法、多层条件随机场方法等。</li>
<li>特征选择：另一种提高NER效果的思路是选择更好的特征表示。通过未登录词和非常规词的识别来提高NER的效果，得到了尝试。为了提高识别的效果，各种全局信息和外部知识如未标注文本（比如知网、未标注文本、人名词典、地名词典等）也作为特征被广泛地应用在NER中。</li>
<li>经典机器学习分类模型如HMM、ME、CRF和SVM都被成功地用来进行命名实体的序列化标注，且获得了较好的效果。</li>
<li>综合的NER方法也取得了较好的效果。比较常见的是模型的混合，如混合多个SVM、混合HMM和ME。统计和规则相结合的方法也较为多见。</li>
</ul>
</li>
<li>
<p>深度学习进行命名实体识别</p>
<ul>
<li>借鉴LSTM在自动分词上得到的较好结果，提出LSTM与CRF相结合的模型是目前主流的方法。</li>
<li>LSTM和基于转换的两种神经网络模型，同时从标注语料和未标注语料中获取特征，也取得了目前较好的实体识别效果。</li>
<li>除此之外，卷积神经网络(CNN)、 混合神经网络(HNN)等深度学习方法也被成功用来解决实体识别问题，并取得了较好的结果。</li>
</ul>
</li>
</ul>
<h2 id="2-%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0">2. 算法实现</h2>
<h3 id="21-%E7%AE%97%E6%B3%95%E7%BB%BC%E8%BF%B0">2.1 算法综述</h3>
<p>我们参照了参考文献[1]中使用双向LSTM和CRF进行实体识别。下图是我们的模型的大致结构。</p>
<p><img src="./pic8.png" alt=""></p>
<p>第一层是 look-up 层，我们使用随机初始化的embedding矩阵将句子中的每个字由one-hot向量映射为$d$维的字向量。在输入下一层之前，我们设置dropout以缓解过拟合。</p>
<p>第二层Bi-LSTM层，它可以有效地使用过去和未来的输入信息，并自动提取句子特征。我们将一个句子的各个字的字向量序列$(x_1, x_2, ..., x_n)$作为Bi-LSTM的输入，然后将正向LSTM输出的隐状态序列$(\vec{h_1}, \vec{h_2}, ..., \vec{h_n})$和反向LSTM在各个位置输出的隐状态$(\stackrel{\leftarrow}{h_1}, \stackrel{\leftarrow}{h_2}, ..., \stackrel{\leftarrow}{h_n})$进行按位置拼接得到完整的隐状态序列:</p>
<p>$(h_1, h_2, ..., h_n) \in \mathbb{R}^{n \times m}$</p>
<p>在设置dropout后，接入一个线性层，将隐状态向量从$m$维映射到$k$维，$k$是标注集的标签数，从而得到自动提取的句子特征，记作矩阵P，接下来将接入一个CRF层来进行标注。</p>
<p>$P = (p_1, p_2, ..., p_n) \in \mathbb{R}^{n \times k}$</p>
<p>CRF层进行句子级别的序列标注，在一个句子中标记每个字符的标记。CRF层的参数是一个$(k+2)×(k+2)$的矩阵$A$ ，$A_{ij}$ 表示的是从第$i$个标签到第$j$个标签的转移得分，从而实现在为一个位置进行标注的时候可以利用此前已经标注过的标签。之所以要加2是因为要为句子首部添加一个起始状态以及为句子尾部添加一个终止状态。如果一个句子的标签序列$y=(y_1,y_2,...,y_n)$，那么模型对于句子$x$的标签等于$y$的打分为：</p>
<p>$S(x, y) = \sum\limits_{k=1}^n{P_{i,y_i}} +  \sum\limits_{k=1}^{n+1}{A_{y_{i-1},y_i}}$</p>
<p>可以看出整个序列的打分等于各个位置的打分之和，而每个位置的打分由两部分得到，一部分是由LSTM输出的$p_i$决定，另一部分则由CRF的转移矩阵$A$决定。进而可以利用Softmax得到归一化后的概率：</p>
<p>$P(y | x) = \frac{exp(S(x, y))}{\sum\limits_{y'}{exp(x, y')}}$</p>
<p>模型训练时通过最大化概率对数似然函数进行训练。</p>
<p>模型在预测过程（解码）时使用动态规划的Viterbi算法来求解最优路径：</p>
<p>$\hat{y} = \mathop{\arg\min}_{y'} S(x, y')$</p>
<p>如果我们使用Softmax层进行标记，我们可能会获得非标记的标记序列，因为Softmax只能独立标记每个位置。我们知道'I-LOC'不能跟随'B-PER'，但Softmax不知道。与Softmax层相比，CRF层可以使用句子级标签信息并模拟每两个不同标签的过渡行为。</p>
<h3 id="22-%E5%AE%9E%E9%AA%8C%E4%BF%A1%E6%81%AF">2.2 实验信息</h3>
<p><strong>实验环境：</strong></p>
<p>tensorflow1.6<br>
python3.5</p>
<p><strong>运行指令：</strong></p>
<p>train(Bi-LSTM + CRF):</p>
<pre class="hljs"><code><div>python main.py --mode=train
</div></code></pre>
<p>train(single Bi-LSTM):</p>
<pre class="hljs"><code><div>python main.py --mode=train --CRF=False
</div></code></pre>
<p>eval(加载检查点文件./data_path_save/1545741134/checkpoints/model-53900,在当前文件夹下产生文件results_eval,然后执行命令python ./data_path/eval.py results_eval ./data_path/dev.txt,得到eval结果):</p>
<pre class="hljs"><code><div>python main.py --mode=test
</div></code></pre>
<p>test(加载检查点文件./data_path_save/1545741134/checkpoints/model-53900，在当前目录下生成结果文件results_test):</p>
<pre class="hljs"><code><div>python test.py 
</div></code></pre>
<h3 id="23-%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B">2.3 训练过程</h3>
<p><strong>模型参数：</strong></p>
<ul>
<li>batch_size：256</li>
<li>hidden_state：300</li>
<li>word_embedding：300</li>
<li>learning rate：0.001</li>
<li>dropout：0.1（使用了dropout来避免过拟合同时提升模型效果）</li>
</ul>
<p><strong>实验过程BiLSTM-CRF的loss曲线图如下：</strong></p>
<p><img src="./pic1.png" alt=""></p>
<p><strong>总体的F值变化如下：</strong></p>
<p><img src="./pic2.png" alt=""></p>
<p><strong>LOC的F值变化：</strong></p>
<p><img src="./pic3.png" alt=""></p>
<p><strong>ORG的F值变化：</strong></p>
<p><img src="./pic4.png" alt=""></p>
<p><strong>PER的F值变化：</strong></p>
<p><img src="./pic5.png" alt=""></p>
<h2 id="3-%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90">3. 结果分析</h2>
<h3 id="31-bi-lstm-crf-%E5%9C%A8%E5%BC%80%E5%8F%91%E9%9B%86%E4%B8%8A%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87">3.1 Bi-LSTM + CRF 在开发集上的准确率</h3>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">precision</th>
<th style="text-align:center">recall</th>
<th style="text-align:center">f1-score</th>
<th style="text-align:center">support</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">PER</td>
<td style="text-align:center">0.8871</td>
<td style="text-align:center">0.8287</td>
<td style="text-align:center">0.8569</td>
<td style="text-align:center">1973</td>
</tr>
<tr>
<td style="text-align:center">LOC</td>
<td style="text-align:center">0.9145</td>
<td style="text-align:center">0.8589</td>
<td style="text-align:center">0.8858</td>
<td style="text-align:center">2877</td>
</tr>
<tr>
<td style="text-align:center">ORG</td>
<td style="text-align:center">0.8682</td>
<td style="text-align:center">0.7724</td>
<td style="text-align:center">0.8175</td>
<td style="text-align:center">1331</td>
</tr>
<tr>
<td style="text-align:center">TOTAL</td>
<td style="text-align:center">0.8958</td>
<td style="text-align:center">0.8306</td>
<td style="text-align:center">0.8619</td>
<td style="text-align:center">6181</td>
</tr>
</tbody>
</table>
<h3 id="32-single-bi-lstm-%E5%9C%A8%E5%BC%80%E5%8F%91%E9%9B%86%E4%B8%8A%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87">3.2 Single Bi-LSTM 在开发集上的准确率</h3>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">precision</th>
<th style="text-align:center">recall</th>
<th style="text-align:center">f1-score</th>
<th style="text-align:center">support</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">PER</td>
<td style="text-align:center">0.8534</td>
<td style="text-align:center">0.7111</td>
<td style="text-align:center">0.7758</td>
<td style="text-align:center">1973</td>
</tr>
<tr>
<td style="text-align:center">LOC</td>
<td style="text-align:center">0.7984</td>
<td style="text-align:center">0.7876</td>
<td style="text-align:center">0.7930</td>
<td style="text-align:center">2877</td>
</tr>
<tr>
<td style="text-align:center">ORG</td>
<td style="text-align:center">0.7462</td>
<td style="text-align:center">0.6228</td>
<td style="text-align:center">0.6790</td>
<td style="text-align:center">1331</td>
</tr>
<tr>
<td style="text-align:center">TOTAL</td>
<td style="text-align:center">0.8047</td>
<td style="text-align:center">0.7277</td>
<td style="text-align:center">0.7629</td>
<td style="text-align:center">6181</td>
</tr>
</tbody>
</table>
<h3 id="33-%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90">3.3 结果分析</h3>
<p>在训练过程中，single Bi-LSTM开发集上准确率明显低于Bi-LSTM+CRF的情况。并且随着 epochs 的提升，在两种方法在开发集上准确率都会随之提升。</p>
<h2 id="4-%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE">4. 参考文献</h2>
<p>[1]Zhiheng Huang, Wei Xu, Kai Yu. Bidirectional LSTM-CRF Models for Sequence Tagging, 2015.</p>
<p>[2]Sun W, Sui Z, Wang M, et al. Chinese Semantic Role Labeling with Shallow Parsing[C]. empirical methods in natural language processing, 2009: 1475-1483.</p>
<p>[3]Zhou J, Xu W. End-to-end learning of semantic role labeling using recurrent neural networks[C]. meeting of the association for computational linguistics, 2015: 1127-1137.</p>
<h2 id="5-%E5%B0%8F%E7%BB%84%E5%88%86%E5%B7%A5">5. 小组分工</h2>
<ul>
<li>
<p>金函琪：</p>
</li>
<li>
<p>王君：</p>
</li>
</ul>

</body>
</html>
